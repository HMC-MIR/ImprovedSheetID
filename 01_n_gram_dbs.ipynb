{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases for each n-gram combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 22 different n-gram combinations (1-3 grams) with maximum context 6. This notebook constructs a database for each type of n-gram and also a database storing the counts for each n-gram type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import dill\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for n_gram in range(1, 4):\n",
    "    combinations += [[0] + list(tup) for tup in itertools.combinations(range(1, 6), n_gram-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [\"\".join(str(num) for num in combination) for combination in combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalBscore(bscore_file):\n",
    "    bscore_array = []\n",
    "    with open(bscore_file,'rb') as f:\n",
    "        bscore_array = pickle.load(f)\n",
    "    total_bscore = np.array([]).reshape(62,0)\n",
    "    for page in bscore_array:\n",
    "        try:\n",
    "            total_page = unpackbits(np.array(page), 62)\n",
    "        except TypeError:\n",
    "            total_page = np.array([]).reshape(62,0)\n",
    "            for num in page:\n",
    "                col = np.array(decodeColumn(num)).reshape(62,-1)\n",
    "                total_page = np.concatenate((total_page,col),axis=1)\n",
    "        total_bscore = np.concatenate((total_bscore,total_page),axis=1)\n",
    "    return total_bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeColumn(num):\n",
    "    col = []\n",
    "    for i in range(62):\n",
    "        col.insert(0,num%2)\n",
    "        num = int(num/2)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackbits(x, num_bits):\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "    return np.flip((x & mask).astype(bool).astype(float), 1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We precompute powers of 2 from $2^0$ to $2^{61}$ to speed up calculating hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = 1 << np.arange(62)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fps(data, combinations, dbs, piece):\n",
    "    for colindex in range(len(data)):\n",
    "        for combination in combinations:\n",
    "            cols = []\n",
    "            # we need at least enough fingerprints for all the indices in our combination\n",
    "            try:\n",
    "                for i in combination:\n",
    "                    cols.append(data[colindex+int(i)])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            fp = []\n",
    "            equals_Zero = True\n",
    "            for column in cols:\n",
    "                hashint = int(column.dot(powers))\n",
    "                fp.append(hashint)\n",
    "                if hashint != 0:\n",
    "                    equals_Zero = False\n",
    "            if equals_Zero == True:\n",
    "                continue\n",
    "            dbs[combination][tuple(fp)][piece].append(colindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate over every query in our list of queries, compute the bootleg score for that query, generate all possible n-grams from the bootleg score, and store it in our database, which is an in-memory Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DB(filelist, combinations, dbs = None):\n",
    "    if not dbs:\n",
    "        dbs = {combination: defaultdict(lambda : defaultdict(list)) for combination in combinations}\n",
    "    with open(filelist, 'r') as f:\n",
    "        failed = []\n",
    "        for i, curfile in enumerate(f):\n",
    "            curfile = curfile.strip().strip('\\n')\n",
    "            try:\n",
    "                num = curfile.split('/')[-1][0]\n",
    "                if num == 'd':\n",
    "                    data = getTotalBscore(curfile)\n",
    "                else:\n",
    "                    with open(curfile, 'rb') as pickle_file:\n",
    "                        data = pickle.load(pickle_file)\n",
    "                make_fps(data.T, combinations, dbs, i)\n",
    "            except:\n",
    "                failed.append(curfile)\n",
    "    return dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_DB(db, combination, outdir):\n",
    "    with open(f\"{outdir}/{combination}.pkl\", \"wb\") as f:\n",
    "        dill.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = 'cfg_files/db.list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = '/data1/kji/databases_random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(db_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a mapping from a number to each piece to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_piece = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filelist, 'r') as f:\n",
    "    failed = []\n",
    "    for i, curfile in enumerate(f):\n",
    "        curfile = curfile.strip().strip('\\n')\n",
    "        piece = curfile.split('/')[-1][:-4]\n",
    "        num_to_piece[i] = piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece_random.pkl\", \"wb\") as f:\n",
    "    pickle.dump(num_to_piece, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece_random.pkl\", 'rb') as f:\n",
    "    num_to_piece = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a database for each n-gram type (total 22). Each n-gram database maps from the n-gram (a tuple) to a dictionary. This dictionary maps each piece that the n-gram appears in to a list of offsets within the piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(combinations), 3):\n",
    "    dbs = make_DB(filelist, combinations[i: i+3])\n",
    "    for combination in dbs:\n",
    "        store_DB(dbs[combination], combination, db_dir)\n",
    "    dbs.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make fingerprint matches table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fingerprint matches table is a nested dictionary. \n",
    "* The first level maps each n-gram type to another dictionary. \n",
    "* The second dictionary maps each n-gram of that type to a tuple (x, y), where x is the total number of times the fingerprint occurs in IMSLP and y is the total number of PDFs in IMSLP with that fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"/data1/kji/databases_random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_matches = {combination: {} for combination in combinations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination in combinations:\n",
    "    with open(f\"{db_dir}/{combination}.pkl\", \"rb\") as f:\n",
    "        d = dill.load(f)\n",
    "    for fp in d:\n",
    "        # first element is number of times the fingerprint occurs, second element is number of PDFs containing the fingerprint\n",
    "        fp_matches[combination][fp] = (sum(len(d[fp][piece]) for piece in d[fp]), len(d[fp]))\n",
    "    d.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
